---
title: "Class 16 notes and code"
output:
  pdf_document: default
  html_document: default
---





$\\$





```{r setup, include=FALSE}

# install.packages("latex2exp")

library(latex2exp)


#options(scipen=999)


knitr::opts_chunk$set(echo = TRUE)

set.seed(123)

```



$\\$




## Overview

 * Data wrangling with dplyr
 * Inference for simple linear regression




$\\$




## Part 1: Data wrangling with dplyr 


We can use the package dplyr to wrangle data. dplyr is part of the 'tidyverse' which is a collection of packages that operate on data frames. 

The main functions in dplyr we will use are:

 * filter()
 * select()
 * mutate()
 * arrange()
 * group_by()
 * summarize()
 * sample_n()
 
Today will will explore the filter(), select(), mutate() and sample_n() functions.  




```{r load_dplyr}

# install.packages('dplyr)

library(dplyr)

```



#### Part 1.1: Loading and viewing the data



To explore these dplyr functions, we will use data from the Integrated Postsecondary Education Data System (IPEDS) which has information about colleges and universities. I have created a subset of this data from 2016 that has information about college salaries, endowment sizes and other variables. Full datasets from several years are available in Microsoft Access format and [can be downloaded here](https://nces.ed.gov/ipeds/use-the-data/download-access-database).

Below is code that loads the data. You can use the View() function from the console to look at the data. The glipse() function in dplyr is also useful for getting a sense of what is in a data frame. 



```{r load_iped}

# download the data
# source('class_functions.R')
# download_class_data("IPED_salaries_2016.rda")


# load the data into R
#load('IPED_salaries_2016.rda')


# View the data from the console
# View(IPED_salaries)


# use dplyr glimpse() function to get a sense of the data


# can also use the base R summary() function to get information on the data


```





$\\$






#### Part 1.2: Filtering to get only Assistant Professor data 


To look at a more homogeneous data set, let's just look at the data for Assistant Professors. To get this subset of the data we can use dplyr's filter() function. We will filter for that and for rank_name of Assistant. We will also filter for colleges that have endowments greater than $0, and get only data where there is no missing information using the complete.cases() function.



```{r filter_salaries}


# filter for assistant professors and endowments greater than $0



# get only the cases that do not have missing data using the complete.cases() function



# get the dimension of this data



```





$\\$






Let's create a boxplot of the data, and also compare the salaries to the salaries at Yale.



```{r}


# create a boxplot comparing Yale to the other schools


# filter to get Yale's data


# add a line with Yale's data to the plot



```



$\\$




#### Part 1.3: Selecting only key variables

The data assistant_data contains several variables we are less interesting in. We can reduce a data frame to just variables we are interested in using the select() function. Let's select the following variables from the data frame:

1) school
2) salary_tot
3) endowment
4) enroll_total


```{r select_vars}


# select the relevant variables: school, salary_tot, endowment and enroll_total


# look at the data frame size



```





$\\$






## Part 2: Inference for simple linear regression using parametric methods


What could be driving the diffrence in faculty salaries across universities? Let's see use linear models to see if we can find variables that predict differences in the salaries professors make at different schools. 



$\\$




#### Part 2.1: Visualizing relationships


One potential factor that could drive differences in faculty salaries is the size of a schools endownment. Let's begin by visualizing the relationship between endowment size and faculty salaries by using a scatter plot. 




```{r visualize_salaries}


```





$\\$






#### Part 2.2: Transforming the explanatory varaibles



Many schools have relatively small endowments compared to other schools and so the relationship does not look particularly linear. To create a better model that can predict salaries it might be useful to transform the predictor varaible endowment by taking the $log_{10}$ of this variable. This will tell us how faculty salaries change with the order of magnitude of a schools endowment. 

One way we can create this transformed variable is to use the dplyr mutate() function. 


```{r mutate_endowment}



# use the mutate() function to create a variable that has the log10 of the endowment



# plot the relationship between salaries and the log10 of a schools endowment



# we can also see a list of schools with the smallest and largest endowments using dplyr's arrange() function




```



$\\$




#### Part 2.3: Fitting a linear model


Let's now fit a linear model to our data to predict faculty salaries from the log10 of the endowment. 



```{r linear_fit}


# fit a regression model  (note: this is y as as function of x)


# plot the data and add the regression line to the plot


# look at the coefficients


```


**Question:**  How do we interpret the coefficients? 








$\\$







#### Part 2.4: Assessing the statistical significance of the fit


We can use R's bulit in summary() function to see if the regression coefficients are statistically significant.



```{r}

# look at whether the regression coefficients are statistically significant (and other information)



```


$\\$





#### Part 2.5: 


We can also use an analysis of variance to assess the statistical significance using an ANOVA with the anova() function applied to our linear model object.  


```{r}


```



**Question** What is the SSModel and SSError here? 




You could also show that SSTotal = SSModel + SSError using data in the `assistant_smaller` data frame (for the SSTotal), and data in the `lm_fit` object (residuals and fitted.values). You will do this on homework 7!




$\\$





#### Part 2.6: t-distribution based confidence intervals

 

We can create confidence intervals using a t-distribution via the confint() function. 



```{r}



```


Interpretation? 




$\\$





#### Part 2.7: Using the bootstrap to create confidence intervals


We can also use resampling methods (i.e., the bootstrap) to get confidence intervals. 

Rather than create confidence intervals here, let's instead use the bootstrap to plot several bootstrap regression lines which will give us a visualizaiton of a range of possible regression lines that could reflect the real underlying relationship. 


```{r}


# let's start by plotting the data



# get the number of cases



# use a loop to plot 100 regression lines that are consistent 

  
  # get a bootstrap sample the same size as the original sample

  
  # fit the regression model on the bootstrap sample and plot it





```




$\\$



